{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! You can use GPU acceleration.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! You can use GPU acceleration.\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU instead.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dump model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creation of the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Paul\\.conda\\envs\\GPU\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "import io\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "\n",
    "def ids_tensor(shape, vocab_size, rng=None, name=None):\n",
    "    #  Creates a random int32 tensor of the shape within the vocab size\n",
    "    import torch\n",
    "\n",
    "    if rng is None:\n",
    "        rng = random.Random()\n",
    "\n",
    "    total_dims = 1\n",
    "    for dim in shape:\n",
    "        total_dims *= dim\n",
    "\n",
    "    values = []\n",
    "    for _ in range(total_dims):\n",
    "        values.append(rng.randint(0, vocab_size - 1))\n",
    "\n",
    "    return torch.tensor(data=values, dtype=torch.long).view(shape).contiguous()\n",
    "\n",
    "\n",
    "def get_llama_model(\n",
    "    input_dims=[(2, 1024)],\n",
    "    hidden_size=1024,  # 4096,\n",
    "    num_hidden_layers=1,\n",
    "    vocab_size=32000,\n",
    "    intermediate_size=11008,\n",
    "    max_position_embeddings=2048,\n",
    "    num_attention_heads=4,  # 32,\n",
    "    _attn_implementation=\"eager\",\n",
    "    with_mask: bool = True,\n",
    "):\n",
    "    import torch\n",
    "    from transformers import LlamaConfig\n",
    "    from transformers.models.llama.modeling_llama import LlamaModel\n",
    "\n",
    "    config = LlamaConfig(\n",
    "        num_hidden_layers=num_hidden_layers,\n",
    "        vocab_size=vocab_size,\n",
    "        hidden_size=hidden_size,\n",
    "        intermediate_size=intermediate_size,\n",
    "        max_position_embeddings=max_position_embeddings,\n",
    "        num_attention_heads=num_attention_heads,\n",
    "    )\n",
    "    if _attn_implementation:\n",
    "        config._attn_implementation = _attn_implementation\n",
    "\n",
    "    class LlamaModelWrapper(torch.nn.Module):\n",
    "        def __init__(self, config):\n",
    "            super().__init__()\n",
    "            self.model = LlamaModel(config)\n",
    "\n",
    "        def forward(self, input_ids, attention_mask):\n",
    "            model_output = self.model(input_ids, attention_mask=attention_mask)\n",
    "            return model_output.to_tuple()\n",
    "\n",
    "    def generate_example_inputs(batch: int, seq: int, vocab_size: int):\n",
    "        input_ids = ids_tensor([batch, seq], vocab_size)\n",
    "        input_mask = torch.tril(torch.ones(batch, seq, dtype=torch.float32))\n",
    "        assert input_mask.dtype == torch.float32\n",
    "        return input_ids, input_mask\n",
    "\n",
    "    example_args_collection = []\n",
    "    for b, s in input_dims:\n",
    "        example_args_collection.append(generate_example_inputs(b, s, vocab_size))\n",
    "\n",
    "    return LlamaModelWrapper(config), example_args_collection\n",
    "\n",
    "\n",
    "print(\"creation of the model.\")\n",
    "model, example_args_collection = get_llama_model()\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaModelWrapper(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 1024)\n",
      "    (layers): ModuleList(\n",
      "      (0): LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=1024, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=1024, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=1024, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Module\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.6538,  1.4923, -1.0207,  ..., -0.9500, -0.6047,  0.2421],\n",
       "          [ 0.5902,  1.5998, -1.2004,  ..., -1.0070, -0.4677,  0.1595],\n",
       "          [ 0.5829,  1.4299, -1.1225,  ..., -1.1021, -0.3678,  0.2983],\n",
       "          ...,\n",
       "          [ 0.5308,  1.5105, -1.1224,  ..., -1.0443, -0.4936,  0.1287],\n",
       "          [ 0.4995,  1.5303, -1.1162,  ..., -1.1316, -0.5139,  0.1244],\n",
       "          [ 0.5986,  1.3492, -1.1980,  ..., -1.0503, -0.5308,  0.0821]],\n",
       " \n",
       "         [[ 1.0960,  0.2340,  0.7139,  ..., -0.1365, -0.6959,  1.3350],\n",
       "          [ 1.0510, -0.8339, -0.3548,  ...,  0.7212, -0.2489,  1.1318],\n",
       "          [ 0.8738,  0.0459,  0.1464,  ...,  0.4444, -0.5898,  1.5109],\n",
       "          ...,\n",
       "          [ 0.8249, -0.5053, -0.2931,  ...,  0.6251,  0.5112,  1.1570],\n",
       "          [ 0.7034, -0.7555, -0.4960,  ...,  0.9936,  0.5579,  0.5991],\n",
       "          [ 0.4533, -0.7071, -0.2579,  ...,  0.1992,  0.0167,  0.8224]]],\n",
       "        grad_fn=<MulBackward0>),\n",
       " ((tensor([[[[-0.1522,  0.6797,  0.9572,  ...,  0.3198, -0.9724,  0.0270],\n",
       "             [-0.8982,  1.1584, -0.5558,  ..., -0.7961, -0.7731,  0.9202],\n",
       "             [-0.9498, -0.1108,  0.9265,  ...,  0.5130, -0.3787,  0.9971],\n",
       "             ...,\n",
       "             [ 0.5406,  0.5220, -0.7081,  ..., -0.6143, -1.4030, -0.7854],\n",
       "             [-0.0938, -0.3428,  0.7025,  ...,  1.5998,  0.2646,  0.3482],\n",
       "             [ 0.1520, -0.5849, -0.4893,  ..., -1.1306, -0.3391,  0.8866]],\n",
       "   \n",
       "            [[-0.3647,  0.2871,  1.1669,  ..., -0.2317,  0.2916,  0.6731],\n",
       "             [-0.9253,  0.0783,  0.5985,  ..., -0.3110,  1.5224, -1.3543],\n",
       "             [ 0.5677, -1.0226, -0.2881,  ...,  0.8428,  1.1561,  0.2600],\n",
       "             ...,\n",
       "             [ 1.1509, -0.6425, -1.5416,  ..., -1.1121, -1.0140,  0.7616],\n",
       "             [ 0.7822, -0.8104,  0.3692,  ...,  0.9830, -0.5868,  0.4083],\n",
       "             [ 1.2662,  0.2304, -1.0390,  ..., -0.4141,  0.0071, -1.2477]],\n",
       "   \n",
       "            [[-0.2963, -0.2265, -1.0068,  ...,  0.2515, -0.0691, -0.1537],\n",
       "             [-0.6790, -0.4577, -0.2099,  ...,  0.5945, -0.1185, -0.9355],\n",
       "             [-0.2654, -0.1967, -0.2409,  ..., -0.8647, -1.2839, -0.2826],\n",
       "             ...,\n",
       "             [-0.2703,  0.7834,  0.2656,  ...,  0.6617, -0.9708,  0.1143],\n",
       "             [-0.1440, -0.2399, -1.0749,  ...,  0.1716,  1.1053,  0.3916],\n",
       "             [-0.1210, -0.5000, -0.6965,  ...,  0.9674, -0.6996,  0.1707]],\n",
       "   \n",
       "            [[ 0.6581, -0.2447,  0.9475,  ..., -0.7208, -0.2393,  0.0211],\n",
       "             [ 0.9801,  0.1324,  0.1546,  ...,  0.4445,  0.2971, -0.7396],\n",
       "             [ 0.4611,  0.5940, -1.0933,  ...,  0.4149,  0.7231,  0.3538],\n",
       "             ...,\n",
       "             [ 0.7293,  1.4991,  0.1010,  ...,  0.7585,  0.3529, -1.1427],\n",
       "             [-0.6912,  0.3884, -0.9433,  ...,  0.3964, -0.0106,  0.9309],\n",
       "             [ 0.1778, -0.0704, -0.2636,  ..., -1.1540,  0.4283, -0.7026]]],\n",
       "   \n",
       "   \n",
       "           [[[ 0.2421,  0.3216,  0.4949,  ...,  1.1544,  0.1000, -0.0198],\n",
       "             [ 0.3425, -0.8450, -0.5063,  ..., -0.6343,  0.9557,  0.4400],\n",
       "             [ 0.6073, -1.1293, -0.9229,  ...,  0.1898, -0.1750,  1.9103],\n",
       "             ...,\n",
       "             [-0.1481,  0.1530,  0.0288,  ...,  0.3737,  0.3279,  0.0089],\n",
       "             [ 0.5856, -0.4208, -0.1189,  ..., -0.0568, -0.3202,  0.5640],\n",
       "             [ 0.9089, -0.4175, -1.9767,  ..., -0.8978, -1.1576,  0.4988]],\n",
       "   \n",
       "            [[-0.3662, -0.5388,  0.7574,  ..., -1.2590, -0.8518, -0.3290],\n",
       "             [ 1.9837, -1.4891, -0.1983,  ..., -0.2221, -0.8950, -0.0606],\n",
       "             [-0.3515, -0.4406, -0.5807,  ...,  0.1041,  0.0585, -0.0579],\n",
       "             ...,\n",
       "             [ 1.1603,  0.2036,  0.2749,  ...,  0.5518,  1.4591, -0.0902],\n",
       "             [ 1.3433, -0.8270,  0.5222,  ..., -0.1179, -0.3325, -0.2231],\n",
       "             [-0.6560, -0.1284, -1.3141,  ...,  0.3641,  0.1679, -0.3251]],\n",
       "   \n",
       "            [[ 0.1586, -0.3887, -0.0138,  ...,  0.5053,  0.4456,  0.7710],\n",
       "             [-0.4750, -0.3569, -0.1105,  ..., -0.4070,  1.0755,  0.2174],\n",
       "             [-0.1877, -0.7963, -0.4515,  ...,  0.2059,  0.0905,  0.1908],\n",
       "             ...,\n",
       "             [-0.4496,  0.0822, -0.9236,  ...,  0.1671, -0.0395,  0.5350],\n",
       "             [-0.3864,  0.3199, -1.1792,  ...,  0.6564,  0.1608, -0.7033],\n",
       "             [-0.9509, -0.0415,  0.1317,  ..., -0.2356,  0.4604,  0.2644]],\n",
       "   \n",
       "            [[ 0.3479,  0.5922,  0.2229,  ..., -0.9844,  0.4652,  0.3123],\n",
       "             [-0.0792, -0.7898,  0.0964,  ...,  0.6061, -0.4153, -0.4038],\n",
       "             [-0.5382,  0.7604,  0.1735,  ...,  0.5424,  0.1207,  0.5263],\n",
       "             ...,\n",
       "             [-0.9291, -0.0657,  0.8926,  ...,  0.3518,  0.8136, -0.5614],\n",
       "             [ 0.6764, -0.6454,  0.3871,  ...,  0.2096, -0.0786,  0.6413],\n",
       "             [ 0.4656, -0.7319,  0.2907,  ...,  1.1485, -0.2576,  0.4214]]]],\n",
       "          grad_fn=<AddBackward0>),\n",
       "   tensor([[[[-4.4402e-01, -1.0175e+00,  9.1148e-02,  ...,  2.5197e-01,\n",
       "              -4.9319e-01, -2.4149e-01],\n",
       "             [-4.2163e-01, -4.5850e-01, -3.9972e-01,  ..., -1.2752e+00,\n",
       "              -1.5774e+00,  8.4547e-01],\n",
       "             [-2.1203e-01,  1.0948e+00, -5.8179e-01,  ...,  2.8085e-01,\n",
       "              -2.7962e-01, -1.1079e+00],\n",
       "             ...,\n",
       "             [-1.9657e-01,  6.5758e-01,  3.1433e-01,  ...,  1.0212e+00,\n",
       "               5.7773e-01,  3.3347e-01],\n",
       "             [-3.0514e-01, -3.6459e-01,  5.7955e-01,  ...,  1.2983e-03,\n",
       "              -2.0163e-01, -5.1230e-01],\n",
       "             [-1.6155e+00,  5.7803e-01, -4.4792e-01,  ..., -1.3505e-01,\n",
       "              -9.9232e-01,  1.0963e+00]],\n",
       "   \n",
       "            [[-1.2912e+00, -2.8767e-01,  2.8179e-01,  ..., -3.6174e-01,\n",
       "              -1.2295e+00, -2.4752e-01],\n",
       "             [ 7.3137e-01,  2.2924e-01,  1.1638e+00,  ..., -1.1387e-01,\n",
       "              -9.3157e-01,  2.3447e-01],\n",
       "             [-2.7014e-01, -4.9525e-01,  2.6432e-01,  ..., -6.8241e-02,\n",
       "              -7.5402e-02, -5.3262e-01],\n",
       "             ...,\n",
       "             [-1.7491e-01, -3.5490e-01, -2.0291e+00,  ..., -1.0394e+00,\n",
       "              -4.7538e-01, -5.5909e-01],\n",
       "             [ 4.1028e-01,  5.6917e-01, -2.4922e-01,  ...,  1.0943e+00,\n",
       "              -2.2984e-01, -5.7520e-01],\n",
       "             [ 5.9534e-01,  8.4455e-01,  2.4417e-02,  ...,  6.0319e-02,\n",
       "               1.2648e+00, -3.5111e-02]],\n",
       "   \n",
       "            [[ 3.3218e-01, -1.3334e+00, -1.8349e+00,  ...,  7.8185e-01,\n",
       "               5.9109e-01,  2.5353e-01],\n",
       "             [-3.8821e-01,  9.0365e-02,  4.7921e-01,  ..., -5.3487e-01,\n",
       "              -7.9662e-01,  2.2086e-01],\n",
       "             [-3.1945e-01,  4.6726e-01, -2.0306e+00,  ..., -7.9326e-02,\n",
       "               4.0620e-02,  3.6082e-02],\n",
       "             ...,\n",
       "             [ 1.0131e+00,  1.1376e+00,  2.6462e-02,  ...,  1.0298e+00,\n",
       "              -5.4834e-01, -6.8710e-01],\n",
       "             [-1.0026e-02,  4.9248e-01,  1.5146e-01,  ...,  4.9030e-01,\n",
       "              -1.1996e-01,  9.4328e-01],\n",
       "             [ 1.0112e+00,  1.9234e-01, -6.5846e-01,  ...,  1.7346e-01,\n",
       "               4.6942e-01, -4.1120e-01]],\n",
       "   \n",
       "            [[ 4.1247e-01,  1.5242e-01,  1.6630e-01,  ...,  1.0232e+00,\n",
       "              -1.9950e-02,  1.6603e-01],\n",
       "             [-7.0589e-01,  1.4931e-01, -5.9726e-01,  ..., -1.1928e+00,\n",
       "               4.5255e-01,  6.4027e-01],\n",
       "             [-1.1046e-01,  8.1646e-01, -1.0823e+00,  ..., -2.2440e-01,\n",
       "              -3.7183e-01, -4.1764e-02],\n",
       "             ...,\n",
       "             [ 5.5640e-01, -2.0723e-01,  6.7524e-03,  ..., -8.8652e-01,\n",
       "              -4.7740e-01,  1.5795e-01],\n",
       "             [-2.9529e-01,  9.7715e-01,  1.4729e-01,  ..., -7.3418e-02,\n",
       "              -4.5378e-01, -2.2538e-01],\n",
       "             [-4.4399e-01, -9.7419e-01,  4.0339e-01,  ...,  5.0136e-01,\n",
       "              -4.7006e-01, -1.0616e+00]]],\n",
       "   \n",
       "   \n",
       "           [[[-8.0140e-01, -1.3329e-01, -2.0922e-01,  ..., -5.4191e-01,\n",
       "              -3.4175e-01, -4.3499e-01],\n",
       "             [ 1.6413e-01, -1.3252e+00,  1.0164e+00,  ..., -6.5558e-02,\n",
       "               5.6167e-01, -1.6687e+00],\n",
       "             [-4.1968e-01,  1.1284e-01,  1.9298e-02,  ...,  8.5203e-01,\n",
       "               2.8900e-02,  1.0845e-01],\n",
       "             ...,\n",
       "             [ 1.0142e+00,  9.2797e-02, -5.5357e-01,  ..., -1.7186e-01,\n",
       "               1.9816e-03,  3.8424e-01],\n",
       "             [ 7.1393e-01, -1.6414e-02, -9.5312e-02,  ...,  2.8005e-01,\n",
       "               3.4736e-01,  1.0904e+00],\n",
       "             [-4.8755e-01, -8.4580e-01, -1.6416e+00,  ..., -4.1972e-01,\n",
       "               9.1594e-03,  2.0602e-01]],\n",
       "   \n",
       "            [[ 1.6993e+00,  1.4268e+00, -2.3628e-01,  ...,  7.1623e-01,\n",
       "              -5.3518e-01,  2.8722e-01],\n",
       "             [ 4.0055e-01,  8.0831e-01, -3.6808e-02,  ...,  4.7556e-01,\n",
       "              -4.6841e-01,  1.3664e+00],\n",
       "             [-7.3669e-01,  5.7053e-01, -4.4190e-01,  ..., -3.1856e-01,\n",
       "              -1.3420e+00,  1.0085e+00],\n",
       "             ...,\n",
       "             [-8.4266e-01, -3.3048e-01,  6.1870e-01,  ..., -1.0854e+00,\n",
       "               1.5524e+00, -2.2783e-01],\n",
       "             [ 5.2243e-02, -1.0934e+00, -5.7714e-02,  ..., -3.6486e-01,\n",
       "              -1.4302e-01, -1.0258e+00],\n",
       "             [-1.8034e-01,  3.5397e-01, -8.9258e-01,  ..., -1.8654e-02,\n",
       "              -2.8380e-01,  9.3827e-01]],\n",
       "   \n",
       "            [[ 3.4368e-01, -8.2835e-01,  1.4998e+00,  ..., -1.9085e-01,\n",
       "               4.3401e-01, -4.8347e-01],\n",
       "             [-9.0797e-02,  2.6654e-01,  4.1414e-02,  ..., -2.8379e-01,\n",
       "              -1.3817e+00, -6.7595e-01],\n",
       "             [ 3.1368e-01, -3.7680e-01,  5.0597e-01,  ..., -8.4706e-01,\n",
       "              -2.6706e-01,  4.6136e-01],\n",
       "             ...,\n",
       "             [ 1.6981e-01,  1.0737e+00, -7.2575e-01,  ...,  8.2870e-01,\n",
       "               1.9792e-01, -1.2824e-01],\n",
       "             [ 3.1109e-01, -8.2359e-01,  1.4163e-01,  ...,  6.4499e-01,\n",
       "               4.1049e-01,  1.5566e+00],\n",
       "             [-2.3251e-01, -4.1203e-01, -1.3105e-01,  ..., -7.2429e-02,\n",
       "              -2.3172e-01, -4.5803e-01]],\n",
       "   \n",
       "            [[-3.1649e-01,  7.1304e-02,  2.3237e-01,  ...,  2.1043e-01,\n",
       "              -3.5426e-01,  4.7821e-01],\n",
       "             [ 3.9905e-01,  1.2112e+00, -8.8610e-01,  ...,  1.3792e+00,\n",
       "               1.6416e+00,  4.6022e-01],\n",
       "             [-7.3430e-01,  1.8120e-01,  4.4585e-01,  ..., -7.7749e-01,\n",
       "               4.6448e-01,  2.3645e-01],\n",
       "             ...,\n",
       "             [-3.1878e-01,  6.0648e-01,  6.8930e-01,  ..., -5.1422e-02,\n",
       "              -3.6786e-01,  7.2147e-01],\n",
       "             [ 1.2826e+00, -2.2837e-01, -3.3992e-01,  ...,  9.9968e-01,\n",
       "               7.2008e-01,  1.3592e+00],\n",
       "             [-4.9550e-01, -3.9511e-01, -1.4909e-01,  ...,  3.2481e-01,\n",
       "               7.9600e-01,  7.0864e-01]]]], grad_fn=<TransposeBackward0>)),))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the model\n",
    "input_dim = (2, 1024)\n",
    "example_arg = example_args_collection[0]\n",
    "model(*example_args_collection[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the dump model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wrapping boils down to:\n",
    "```\n",
    "- wrapper\n",
    "    - model\n",
    "        - LlamaDecoderLayer\n",
    "```\n",
    "The model then is:  \n",
    "![Llama model](llama.jpg)\n",
    "\n",
    "Which corresponds on the netron model to:  \n",
    "![Netron labeled](llama_netron_labeled.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step by step\n",
    "from transformers.cache_utils import Cache, DynamicCache, StaticCache\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPast\n",
    "\n",
    "# args\n",
    "input_ids, attention_mask = example_arg\n",
    "_model = model.model\n",
    "\n",
    "# Forward\n",
    "output_attentions = _model.config.output_attentions\n",
    "output_hidden_states = _model.config.output_hidden_states\n",
    "use_cache = _model.config.use_cache\n",
    "return_dict = _model.config.use_return_dict\n",
    "inputs_embeds = _model.embed_tokens(input_ids)\n",
    "\n",
    "past_seen_tokens = 0\n",
    "if not isinstance(None, StaticCache):\n",
    "    past_key_values = DynamicCache.from_legacy_cache(None)\n",
    "    past_seen_tokens = past_key_values.get_seq_length()\n",
    "\n",
    "if isinstance(past_key_values, StaticCache):\n",
    "    raise ValueError(\"cache_position is a required argument when using StaticCache.\")\n",
    "cache_position = torch.arange(\n",
    "    past_seen_tokens, past_seen_tokens + inputs_embeds.shape[1], device=inputs_embeds.device\n",
    ")\n",
    "\n",
    "position_ids = cache_position.unsqueeze(0)\n",
    "causal_mask = _model._update_causal_mask(attention_mask, inputs_embeds, cache_position, past_seen_tokens)\n",
    "\n",
    "# embed positions\n",
    "hidden_states = inputs_embeds\n",
    "\n",
    "# decoder layers\n",
    "all_hidden_states = None\n",
    "all_self_attns = None\n",
    "next_decoder_cache = None\n",
    "\n",
    "decoder_layer = _model.layers[0]\n",
    "\n",
    "# forward from decoder layer\n",
    "attention_mask=causal_mask\n",
    "position_ids=position_ids\n",
    "past_key_value=past_key_values\n",
    "output_attentions=output_attentions\n",
    "use_cache=use_cache\n",
    "cache_position=cache_position\n",
    "\n",
    "residual = hidden_states\n",
    "hidden_states = decoder_layer.input_layernorm(hidden_states) # hidden_states is x\n",
    "\n",
    "# Self Attention\n",
    "hidden_states, self_attn_weights, present_key_value = decoder_layer.self_attn(\n",
    "    hidden_states=hidden_states,\n",
    "    attention_mask=attention_mask,\n",
    "    position_ids=position_ids,\n",
    "    past_key_value=past_key_value,\n",
    "    output_attentions=output_attentions,\n",
    "    use_cache=use_cache,\n",
    "    cache_position=cache_position\n",
    ")\n",
    "hidden_states = residual + hidden_states\n",
    "\n",
    "# Fully Connected\n",
    "residual = hidden_states\n",
    "hidden_states = decoder_layer.post_attention_layernorm(hidden_states)\n",
    "mlp_input = hidden_states # for mlp fuzed kernel\n",
    "hidden_states = decoder_layer.mlp(hidden_states)\n",
    "hidden_states = residual + hidden_states\n",
    "\n",
    "outputs = (hidden_states,)\n",
    "\n",
    "# if output_attentions:\n",
    "#     outputs += (self_attn_weights,)\n",
    "\n",
    "outputs += (present_key_value,)\n",
    "\n",
    "layer_outputs = outputs\n",
    "# end of forward from decoder layer\n",
    "\n",
    "hidden_states = layer_outputs[0]\n",
    "\n",
    "next_decoder_cache = layer_outputs[2 if output_attentions else 1]\n",
    "\n",
    "hidden_states = _model.norm(hidden_states)\n",
    "\n",
    "# add hidden states from the last decoder layer\n",
    "if output_hidden_states:\n",
    "    all_hidden_states += (hidden_states,)\n",
    "\n",
    "next_cache = None\n",
    "if use_cache:\n",
    "    next_cache = (\n",
    "        next_decoder_cache.to_legacy_cache() if isinstance(next_decoder_cache, Cache) else next_decoder_cache\n",
    "    )\n",
    "\n",
    "_return = BaseModelOutputWithPast(\n",
    "last_hidden_state=hidden_states,\n",
    "past_key_values=next_cache,\n",
    "hidden_states=all_hidden_states,\n",
    "attentions=all_self_attns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mlp fuzed kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate the MLP\n",
    "mlp = decoder_layer.mlp\n",
    "torch.onnx.export(\n",
    "    mlp,\n",
    "    (mlp_input,),\n",
    "    \"mlp.onnx\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `mlp` module actually correspond to a gated multi-layer perceptron.  \n",
    "See https://arxiv.org/pdf/2002.05202 as a reference (we later call the Swish function SiLU). \n",
    "The gated linear unit returns:  \n",
    "`self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))`, that is to say:\n",
    "$$(\\sigma(X \\times G^T) \\odot (X \\times U^T)) \\times D^T$$\n",
    "With the shapes:\n",
    "- $X: n,d$\n",
    "- $U: \\tilde{d},d$\n",
    "- $G: \\tilde{d},d$\n",
    "- $D: d,\\tilde{d}$  \n",
    "\n",
    "$\\sigma$ corresponds to the $SiLU$ activation function: $\\sigma(x)=x*sigmoid(x)$\n",
    "\n",
    "![MLP netron labeled](mlp_netron_labeled.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "hidden_size = _model.config.hidden_size\n",
    "intermediate_size = _model.config.intermediate_size\n",
    "mlp_input_shape = mlp_input.shape\n",
    "G = mlp.gate_proj.weight\n",
    "U = mlp.up_proj.weight\n",
    "D = mlp.down_proj.weight\n",
    "\n",
    "# Forward\n",
    "X = mlp_input\n",
    "output = mlp(mlp_input)\n",
    "act_fn = torch.nn.SiLU()\n",
    "_ = (act_fn(X@G.T)*(X@U.T)) @ D.T\n",
    "assert torch.allclose(output, _)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "torch.save(mlp,\"mlp.pt\")\n",
    "torch.save(mlp_input,\"mlp_input.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triton kernel\n",
    "https://developer.nvidia.com/blog/cuda-refresher-cuda-programming-model/  \n",
    "https://triton-lang.org/main/getting-started/tutorials/01-vector-add.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start by exploring my GPU characteristics, using CUDA demo suite `deviceQuery` (`Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.1\\extras\\demo_suite`):\n",
    "```\n",
    "Device 0: \"NVIDIA GeForce GTX 950M\"\n",
    "  CUDA Driver Version / Runtime Version          12.1 / 12.1\n",
    "  CUDA Capability Major/Minor version number:    5.0\n",
    "  Total amount of global memory:                 2048 MBytes (2147352576 bytes)\n",
    "  ( 5) Multiprocessors, (128) CUDA Cores/MP:     640 CUDA Cores\n",
    "  GPU Max Clock rate:                            1124 MHz (1.12 GHz)\n",
    "  Memory Clock rate:                             1001 Mhz\n",
    "  Memory Bus Width:                              128-bit\n",
    "  L2 Cache Size:                                 2097152 bytes\n",
    "  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n",
    "  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n",
    "  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n",
    "  Total amount of constant memory:               zu bytes\n",
    "  Total amount of shared memory per block:       zu bytes\n",
    "  Total number of registers available per block: 65536\n",
    "  Warp size:                                     32\n",
    "  Maximum number of threads per multiprocessor:  2048\n",
    "  Maximum number of threads per block:           1024\n",
    "  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n",
    "  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n",
    "  Maximum memory pitch:                          zu bytes\n",
    "  Texture alignment:                             zu bytes\n",
    "  Concurrent copy and kernel execution:          Yes with 4 copy engine(s)\n",
    "  Run time limit on kernels:                     Yes\n",
    "  Integrated GPU sharing Host Memory:            No\n",
    "  Support host page-locked memory mapping:       Yes\n",
    "  Alignment requirement for Surfaces:            Yes\n",
    "  Device has ECC support:                        Disabled\n",
    "  CUDA Device Driver Mode (TCC or WDDM):         WDDM (Windows Display Driver Model)\n",
    "  Device supports Unified Addressing (UVA):      Yes\n",
    "  Device supports Compute Preemption:            No\n",
    "  Supports Cooperative Kernel Launch:            No\n",
    "  Supports MultiDevice Co-op Kernel Launch:      No\n",
    "  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\n",
    "  Compute Mode:\n",
    "     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n",
    "```\n",
    "\n",
    "I need to compute:\n",
    "$$\n",
    "\\begin{cases}\n",
    "    Z =  & X \\times G^T\\\\\n",
    "    \\tilde{Z} = & Z \\odot sigmoid(Z) \\odot (X\\times U^T)\\\\\n",
    "    ... = & \\tilde{Z} \\times D^T\n",
    "  \\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I propose the following parallelization scheme:\n",
    "- Compute $Z$ and $X \\times U^T$ in parallel\n",
    "- Compute $sigmoid(Z)$\n",
    "- Compute the triple element wise multiplication for $\\tilde{Z}$\n",
    "- Compute $\\tilde{Z} \\times D^T$  \n",
    "\n",
    "The first step is natively implemented when using\n",
    "$X \\times ( \n",
    "    \\begin{array}{c}\n",
    "    G^T \\\\\n",
    "    U^T \\\\\n",
    "    \\end{array}\n",
    "    )$\n",
    "and masks to retrieve results.\n",
    "The novelty is step 3, that is to say a kernel for triple elementwise matrix multiplication.\n",
    "Performance improvements from other steps will not come from parallelization but from cach usage optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a naive implementation, I get the following performance:  \n",
    "![Naive triton kernel](figures/naive_triton_kernel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUSED MLP kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max between triton fp8 and without fp8 in triton tensor(3.9375, device='cuda:0', dtype=torch.float16)\n",
      "max between pytorch and triton(without fp8) tensor(0., device='cuda:0', dtype=torch.float16)\n",
      "max between pytorch and triton(without fp8) tensor(3.9375, device='cuda:0', dtype=torch.float16)\n",
      "✅ Triton and Torch match in the range of 1e-1\n",
      "rms matmul silu mul pytorch 0.6611626744270325\n",
      "rms matmul silu mul triton 0.5943467020988464\n",
      "rms matmul silu mul triton fp8 0.5135359764099121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "from triton_kernel import kernel_ff\n",
    "from pytorch_kernel import ff_pytorch\n",
    "from pytorch_kernel import rms_norm_pytorch\n",
    "\n",
    "from utils import f16_to_f8\n",
    "\n",
    "# standard deviation of the weight distribution is 0.2 for numerical stability\n",
    "\n",
    "rms_w = torch.randn([4096], dtype=torch.float16, device=\"cuda\") * 0.2\n",
    "x = torch.randn([1, 16, 4096], dtype=torch.float16, device=\"cuda\")\n",
    "x = rms_norm_pytorch(x, rms_w, eps=1e-6)\n",
    "\n",
    "# weights tend to be very small values\n",
    "w1_w = torch.randn([11008, 4096], dtype=torch.float16, device=\"cuda\") * 0.2\n",
    "w3_w = torch.randn([11008, 4096], dtype=torch.float16, device=\"cuda\") * 0.2\n",
    "\n",
    "# Convert weights to FP8 and test the Triton kernel with FP8 weights\n",
    "w1_w_fp8 = f16_to_f8(w1_w, dtypes=tl.float8e5)\n",
    "w3_w_fp8 = f16_to_f8(w3_w, dtypes=tl.float8e5)\n",
    "\n",
    "\n",
    "# Compare Triton and PyTorch outputs\n",
    "output_triton = kernel_ff(x=x, w1=w1_w, w3=w3_w)\n",
    "output_triton_fp8 = kernel_ff(x=x, w1=w1_w_fp8, w3=w3_w_fp8)\n",
    "output_pytorch = ff_pytorch(x=x, w1=w1_w, w3=w3_w)\n",
    "\n",
    "\n",
    "# max difference between the three implementations\n",
    "print(\"max between triton fp8 and without fp8 in triton\",max(torch.abs(output_triton - output_triton_fp8).flatten()))\n",
    "print(\"max between pytorch and triton(without fp8)\",max(torch.abs(output_triton - output_triton).flatten()))\n",
    "print(\"max between pytorch and triton(without fp8)\",max(torch.abs(output_triton - output_triton_fp8).flatten()))\n",
    "\n",
    "# Validate the results\n",
    "if torch.allclose(output_triton, output_pytorch, atol=1e-1):\n",
    "    print(\"✅ Triton and Torch match in the range of 1e-1\")\n",
    "else:\n",
    "    print(\"❌ Triton and Torch differ in the range of 1e-1\")\n",
    "\n",
    "# Benchmarking the PyTorch implementation\n",
    "print(\"rms matmul silu mul pytorch\", triton.testing.do_bench(lambda: ff_pytorch(x=x, w1=w1_w, w3=w3_w)))\n",
    "\n",
    "# Benchmarking the Triton implementation without FP8 weights\n",
    "print(\"rms matmul silu mul triton\", triton.testing.do_bench(lambda: kernel_ff(x=x, w1=w1_w, w3=w3_w)))\n",
    "\n",
    "# Benchmarking the Triton implementation with FP8 weights\n",
    "# when use fp8, on very large tensors, it is expected that the error is large, we just check it is not crazy large\n",
    "print(\"rms matmul silu mul triton fp8\", triton.testing.do_bench(lambda: kernel_ff(x=x, w1=w1_w_fp8, w3=w3_w_fp8)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `triton.testing.do_bench` fournit des informations détaillées sur la performance de la fonction `kernel_ff` en termes de temps d'exécution sur le GPU, ce qui est crucial pour évaluer et optimiser les performances des noyaux CUDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fused RMSnorm + MLP kernel into one "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![RMSNorm](figures/RMSNorm_arxiv.png)\n",
    "\n",
    "\n",
    "See https://arxiv.org/abs/1910.07467 as a reference. \n",
    "\n",
    "and then on X_normalized\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "    Z =  & X_{normalized} \\times G^T\\\\\n",
    "    \\tilde{Z} = & Z \\odot sigmoid(Z) \\odot (X_{normalized}\\times U^T)\\\\\n",
    "    ... = & \\tilde{Z} \\times D^T\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l'idée est de combiner 2 étapes de calcul en une seule boucle optimisée, réduisant ainsi les redondances de loader l'output après la normalisation pour améliorer l'efficacité globale du modèle.\n",
    "\n",
    "\n",
    "L'objectif est d'optimiser la section feed-forward du modèle LLAMA pour améliorer les performances. Voici les étapes et l'idée générale de ce que nous voulons coder :\n",
    "\n",
    "1. **Normalisation RMS (RMSNorm) :** Appliquer une normalisation RMS à l'entrée une seule fois et réutiliser cette sortie normalisée pour les opérations suivantes. Actuellement, `x_norm` est calculé une fois puis utilisé dans deux multiplications matricielles séparées.\n",
    "\n",
    "2. **Multiplications Matricielles en Chaîne :** Enchaîner les deux multiplications matricielles dans une seule boucle pour réduire les accès mémoire et améliorer l'efficacité. La première multiplication matricielle est suivie par une opération `silu` (qui combine une multiplication et une activation sigmoïde), puis une deuxième multiplication matricielle est effectuée.\n",
    "\n",
    "3. **Fusion des Opérations :** Fusionner l'opération `silu` avec la sortie de la première multiplication matricielle pour éviter des opérations redondantes. Cette fusion implique de combiner les opérations élémentaires de manière à ce qu'elles soient effectuées en une seule étape.\n",
    "\n",
    "4. **Optimisation des Statistiques RMS :** Calculer et appliquer les statistiques RMS dans la même boucle que les multiplications matricielles, réduisant ainsi le nombre de passes nécessaires sur les données.\n",
    "\n",
    "5. **Amélioration des Performances :** En rationalisant ces opérations, le nouveau noyau sera plus rapide que l'implémentation actuelle en PyTorch. Les optimisations visent à réduire le temps d'exécution en minimisant les opérations redondantes et en améliorant l'utilisation des ressources.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Triton and Torch match in the range of 1e-1\n",
      "rms matmul silu mul pytorch 0.7123625874519348\n",
      "rms matmul silu mul triton fp8 0.5419417023658752\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "from triton_kernel import kernel_ff_with_rmsnorm\n",
    "from pytorch_kernel import ff_pytorch_with_rmsnorm\n",
    "\n",
    "from utils import f16_to_f8\n",
    "\n",
    "# Example usage\n",
    "x = torch.randn([1, 16, 4096], dtype=torch.float16, device=\"cuda\")\n",
    "# weights tends to be very small values\n",
    "rms_w = torch.randn([4096], dtype=torch.float16, device=\"cuda\") * 0.2\n",
    "w1_w = torch.randn([11008, 4096], dtype=torch.float16, device=\"cuda\") * 0.2\n",
    "w3_w = torch.randn([11008, 4096], dtype=torch.float16, device=\"cuda\") * 0.2\n",
    "\n",
    "\n",
    "# Compare Triton and PyTorch outputs\n",
    "output_triton = kernel_ff_with_rmsnorm(x=x, w1=w1_w, w3=w3_w, rms_w=rms_w)\n",
    "output_pytorch = ff_pytorch_with_rmsnorm(x=x, w1=w1_w, w3=w3_w, rms_w=rms_w)\n",
    "\n",
    "# Validate the results\n",
    "if torch.allclose(output_triton, output_pytorch, atol=1e-1):\n",
    "    print(\"✅ Triton and Torch match in the range of 1e-1\")\n",
    "else:\n",
    "    print(\"❌ Triton and Torch differ in the range of 1e-1\")\n",
    "\n",
    "# Benchmarking the PyTorch implementation\n",
    "print(\"rms matmul silu mul pytorch\", triton.testing.do_bench(lambda: ff_pytorch_with_rmsnorm(x=x, w1=w1_w, w3=w3_w, rms_w=rms_w)))\n",
    "\n",
    "# Convert weights to FP8 and test the Triton kernel with FP8 weights\n",
    "w1_w_fp8 = f16_to_f8(w1_w, dtypes=tl.float8e5)\n",
    "w3_w_fp8 = f16_to_f8(w3_w, dtypes=tl.float8e5)\n",
    "rms_w_fp8 = f16_to_f8(rms_w, dtypes=tl.float8e5)\n",
    "\n",
    "out_fp8 = kernel_ff_with_rmsnorm(x=x, w1=w1_w_fp8, w3=w3_w_fp8, rms_w=rms_w_fp8)\n",
    "\n",
    "\n",
    "# Benchmarking the Triton implementation with FP8 weights\n",
    "print(\"rms matmul silu mul triton fp8\", triton.testing.do_bench(lambda: kernel_ff_with_rmsnorm(x=x, w1=w1_w_fp8, w3=w3_w_fp8, rms_w=rms_w_fp8)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `triton.testing.do_bench` fournit des informations détaillées sur la performance de la fonction `kernel_ff` en termes de temps d'exécution sur le GPU, ce qui est crucial pour évaluer et optimiser les performances des noyaux CUDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark performance when variyng input  size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel-performance:\n",
      "         N    Triton  Torch (native)\n",
      "0    256.0  0.449246        0.622672\n",
      "1    384.0  0.459698        0.818158\n",
      "2    512.0  0.461828        0.902009\n",
      "3    640.0  0.456369        0.369434\n",
      "4    768.0  0.463604        0.385264\n",
      "5    896.0  0.460598        0.384158\n",
      "6   1024.0  0.458980        0.476753\n",
      "7   1152.0  0.454948        0.517831\n",
      "8   1280.0  0.438765        0.573337\n",
      "9   1408.0  0.373248        0.566491\n",
      "10  1536.0  0.342950        0.603711\n",
      "11  1664.0  0.314879        0.650526\n",
      "12  1792.0  0.281762        0.671141\n",
      "13  1920.0  0.255173        0.551749\n",
      "14  2048.0  0.266399        0.715606\n",
      "15  2176.0  0.264384        0.782418\n",
      "16  2304.0  0.247185        0.801155\n",
      "17  2432.0  0.200414        0.758847\n"
     ]
    }
   ],
   "source": [
    "@triton.testing.perf_report(\n",
    "    triton.testing.Benchmark(\n",
    "        x_names=['N'],  # argument names to use as an x-axis for the plot\n",
    "        x_vals=[128 * i for i in range(2, 20)],  # Réduisez la plage des valeurs de `N`\n",
    "        line_arg='provider',  # argument name whose value corresponds to a different line in the plot\n",
    "        line_vals=[\n",
    "            'triton',\n",
    "            'torch-native',\n",
    "        ],  # possible values for `line_arg`\n",
    "        line_names=[\n",
    "            \"Triton\",\n",
    "            \"Torch (native)\",\n",
    "        ],  # label name for the lines\n",
    "        styles=[('blue', '-'), ('green', '-')],  # line styles\n",
    "        ylabel=\"GB/s\",  # label name for the y-axis\n",
    "        plot_name=\"kernel-performance\",  # name for the plot. Used also as a file name for saving the plot.\n",
    "        args={'M': 4096},  # values for function arguments not in `x_names` and `y_name`\n",
    "    ))\n",
    "def benchmark(M, N, provider):\n",
    "    batch = 20\n",
    "    seq_len = M\n",
    "    dim = N\n",
    "    x = torch.randn(batch, seq_len, dim, device='cuda', dtype=torch.float16)\n",
    "    w1 = torch.randn(11008, dim, device='cuda', dtype=torch.float16) * 0.2\n",
    "    w3 = torch.randn(11008, dim, device='cuda', dtype=torch.float16) * 0.2\n",
    "    rms_w = torch.randn(dim, device='cuda', dtype=torch.float16) * 0.2\n",
    "    quantiles = [0.5, 0.2, 0.8]\n",
    "\n",
    "    if provider == 'torch-native':\n",
    "        #ms, min_ms, max_ms = triton.testing.do_bench(lambda: ff_pytorch(x, w1, w3), quantiles=quantiles)\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: ff_pytorch_with_rmsnorm(x, w1, w3,rms_w), quantiles=quantiles)\n",
    "    elif provider == 'triton':\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: kernel_ff(x, w1, w3), quantiles=quantiles)\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: kernel_ff_with_rmsnorm(x, w1, w3,rms_w), quantiles=quantiles)\n",
    "    gbps = lambda ms: 2 * x.nelement() * x.element_size() * 1e-9 / (ms * 1e-3)\n",
    "    return gbps(ms), gbps(max_ms), gbps(min_ms)\n",
    "\n",
    "benchmark.run(show_plots=True, print_data=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
